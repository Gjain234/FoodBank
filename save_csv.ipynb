{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import nbformat\n",
    "import plotly.express\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import scipy.optimize as optimization\n",
    "import food_bank_functions\n",
    "import food_bank_bayesian\n",
    "from food_bank_functions import *\n",
    "from food_bank_bayesian import *\n",
    "importlib.reload(food_bank_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_policy = np.loadtxt('opt_policy.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Number of Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 1000\n",
    "max_n = 1000\n",
    "grid_size = .01\n",
    "sorted_distribution = np.arange(2) + 1\n",
    "weights = np.zeros(2)+0.5\n",
    "expected_demand = np.dot(sorted_distribution,weights)\n",
    "max_budget = max_n*expected_demand\n",
    "b_grid = np.arange(0, max_budget+grid_size, grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Norm between OPT and ALGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_1 = {'NumGroups':[],'Dynamic':[],'Weights':[], 'Bayes':[], 'Threshold':[],'Greedy':[]}\n",
    "for n in np.logspace(0,3,100):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + expected_demand    \n",
    "    budget = n*expected_demand\n",
    "    for i in range(num_iterations):\n",
    "        data_dict_1['NumGroups'].append(n)\n",
    "        group_demands = np.random.randint(1, 3, n)\n",
    "        opt = waterfilling_waste(group_demands,budget)\n",
    "        data_dict_1['Weights'].append(np.sum(np.absolute(opt - waterfilling_weights_waste(weights, sorted_distribution, group_demands, budget))))\n",
    "        data_dict_1['Dynamic'].append(np.sum(np.absolute(opt - waterfilling_dynamic_waste(group_expected_demands,group_demands,budget))))\n",
    "        data_dict_1['Bayes'].append(np.sum(np.absolute(opt - waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size))))\n",
    "        data_dict_1['Greedy'].append(np.sum(np.absolute(opt - greedy(group_demands,budget))))\n",
    "        data_dict_1['Threshold'].append(np.sum(np.absolute(opt - constant_threshold(group_demands,budget,expected_demand))))                                                  \n",
    "df_uniform = pd.DataFrame(data_dict_1).melt(id_vars=\"NumGroups\")\n",
    "df_uniform.to_csv('L1.csv')\n",
    "fig = px.scatter(df_uniform, x=\"NumGroups\", y=\"value\", color='variable')\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"L1 Distance between OPT and ALGs\",\n",
    "    xaxis_title=\"Number of Groups\",\n",
    "    yaxis_title=\"Distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-Inf Norm between OPT and ALGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_1 = {'NumGroups':[],'Dynamic':[],'Weights':[], 'Bayes':[], 'Threshold':[],'Greedy':[]}\n",
    "\n",
    "for n in np.logspace(0,3,100):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + expected_demand    \n",
    "    budget = n*expected_demand\n",
    "    for i in range(num_iterations):\n",
    "        data_dict_1['NumGroups'].append(n)\n",
    "        group_demands = np.random.randint(1, 3, n)\n",
    "        opt = waterfilling_waste(group_demands,budget)\n",
    "        data_dict_1['Weights'].append(np.amax(np.absolute(opt - waterfilling_weights_waste(weights, sorted_distribution, group_demands, budget))))\n",
    "        data_dict_1['Dynamic'].append(np.amax(np.absolute(opt - waterfilling_dynamic_waste(group_expected_demands,group_demands,budget))))\n",
    "        data_dict_1['Bayes'].append(np.amax(np.absolute(opt - waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size))))\n",
    "        data_dict_1['Greedy'].append(np.amax(np.absolute(opt - greedy(group_demands,budget))))\n",
    "        data_dict_1['Threshold'].append(np.amax(np.absolute(opt - constant_threshold(group_demands,budget,expected_demand))))\n",
    "df_uniform = pd.DataFrame(data_dict_1).melt(id_vars=\"NumGroups\")\n",
    "df_uniform.to_csv('L-Inf.csv')\n",
    "fig = px.scatter(df_uniform, x=\"NumGroups\", y=\"value\", color='variable')\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"L-Inf Distance between OPT and ALGs\",\n",
    "    xaxis_title=\"Number of Groups\",\n",
    "    yaxis_title=\"Distance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nash Welfare Regret wrt OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_1 = {'NumGroups':[],'Dynamic':[],'Weights':[], 'Bayes':[], 'Threshold':[],'Greedy':[]}\n",
    "\n",
    "for n in np.logspace(0,3,100):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + expected_demand    \n",
    "    budget = n*expected_demand\n",
    "    for i in range(num_iterations):\n",
    "        data_dict_1['NumGroups'].append(n)\n",
    "        group_demands = np.random.randint(1, 3, n)\n",
    "        opt = objective_nash(group_demands, waterfilling_waste(group_demands,budget))\n",
    "        data_dict_1['Weights'].append(opt - objective_nash(group_demands, waterfilling_weights_waste(weights, sorted_distribution, group_demands, budget)))\n",
    "        data_dict_1['Dynamic'].append(opt - objective_nash(group_demands, waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)))\n",
    "        data_dict_1['Bayes'].append(opt - objective_nash(group_demands, waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)))\n",
    "        data_dict_1['Threshold'].append(opt - objective_nash(group_demands, constant_threshold(group_demands,budget,expected_demand)))\n",
    "        data_dict_1['Greedy'].append(opt - objective_nash(group_demands, greedy(group_demands,budget)))\n",
    "df_uniform = pd.DataFrame(data_dict_1).melt(id_vars=\"NumGroups\")\n",
    "df_uniform.to_csv('Nash.csv')\n",
    "fig = px.scatter(df_uniform, x=\"NumGroups\", y=\"value\", color='variable')\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"Nash Welfare Regret wrt OPT\",\n",
    "    xaxis_title=\"Number of Groups\",\n",
    "    yaxis_title=\"Regret\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Nash Welfare Regret wrt OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_1 = {'NumGroups':[],'Dynamic':[],'Weights':[], 'Bayes':[], 'Threshold':[],'Greedy':[]}\n",
    "\n",
    "for n in np.logspace(0,3,100):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + expected_demand    \n",
    "    budget = n*expected_demand\n",
    "    for i in range(num_iterations):\n",
    "        data_dict_1['NumGroups'].append(n)\n",
    "        group_demands = np.random.randint(1, 3, n)\n",
    "        opt = objective_nash_log(group_demands, waterfilling_waste(group_demands,budget))\n",
    "        data_dict_1['Weights'].append(opt - objective_nash_log(group_demands, waterfilling_weights_waste(weights, sorted_distribution, group_demands, budget)))\n",
    "        data_dict_1['Dynamic'].append(opt - objective_nash_log(group_demands, waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)))\n",
    "        data_dict_1['Bayes'].append(opt - objective_nash_log(group_demands, waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)))\n",
    "        data_dict_1['Greedy'].append(opt - objective_nash_log(group_demands, greedy(group_demands,budget)))\n",
    "        data_dict_1['Threshold'].append(opt - objective_nash_log(group_demands, constant_threshold(group_demands,budget,expected_demand)))\n",
    "df_uniform = pd.DataFrame(data_dict_1).melt(id_vars=\"NumGroups\")\n",
    "df_uniform.to_csv('LogNash.csv')\n",
    "fig = px.scatter(df_uniform, x=\"NumGroups\", y=\"value\", color='variable')\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"Log Nash Welfare Regret  wrt OPT\",\n",
    "    xaxis_title=\"Number of Groups\",\n",
    "    yaxis_title=\"Regret\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMALIZED Log Nash Welfare Regret wrt OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_1 = {'NumGroups':[],'Dynamic':[],'Weights':[], 'Bayes':[], 'Threshold':[],'Greedy':[]}\n",
    "\n",
    "for n in np.logspace(0,3,100):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + expected_demand    \n",
    "    budget = n*expected_demand\n",
    "    for i in range(num_iterations):\n",
    "        data_dict_1['NumGroups'].append(n)\n",
    "        group_demands = np.random.randint(1, 3, n)\n",
    "        opt = objective_nash_log_normalized(group_demands, waterfilling_waste(group_demands,budget))\n",
    "        data_dict_1['Weights'].append(opt - objective_nash_log_normalized(group_demands, waterfilling_weights_waste(weights, sorted_distribution, group_demands, budget)))\n",
    "        data_dict_1['Dynamic'].append(opt - objective_nash_log_normalized(group_demands, waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)))\n",
    "        data_dict_1['Bayes'].append(opt - objective_nash_log_normalized(group_demands, waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)))\n",
    "        data_dict_1['Greedy'].append(opt - objective_nash_log_normalized(group_demands, greedy(group_demands,budget)))\n",
    "        data_dict_1['Threshold'].append(opt - objective_nash_log_normalized(group_demands, constant_threshold(group_demands,budget,expected_demand)))\n",
    "df_uniform = pd.DataFrame(data_dict_1).melt(id_vars=\"NumGroups\")\n",
    "df_uniform.to_csv('LogNashNormal.csv')\n",
    "fig = px.scatter(df_uniform, x=\"NumGroups\", y=\"value\", color='variable')\n",
    "fig.update_layout(xaxis_type=\"log\", yaxis_type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"Normalized Log Nash Welfare Regret wrt OPT\",\n",
    "    xaxis_title=\"Number of Groups\",\n",
    "    yaxis_title=\"Regret\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Number of Groups: Group by Group Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 1000\n",
    "grid_size = .01\n",
    "sorted_distribution = np.arange(2) + 1\n",
    "weights = np.zeros(2)+0.5\n",
    "expected_demand = np.dot(sorted_distribution,weights)\n",
    "n=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Comparisons using Sum of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = np.arange(n)\n",
    "group_expected_demands = np.zeros(n) + 1.5\n",
    "budget = 1.5*n\n",
    "score_weights = np.zeros((n,num_iterations))\n",
    "score_bayes = np.zeros((n,num_iterations))\n",
    "score_dynamic = np.zeros((n,num_iterations))\n",
    "score_greedy = np.zeros((n,num_iterations))\n",
    "score_threshold = np.zeros((n,num_iterations))\n",
    "env = np.zeros((5,num_iterations))\n",
    "po = np.zeros((5,num_iterations))\n",
    "prop = np.zeros((5,num_iterations))\n",
    "for i in range(num_iterations):\n",
    "    group_demands = np.random.randint(1, 3, n)\n",
    "    opt = waterfilling_waste(group_demands,budget)\n",
    "    bayes = waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)\n",
    "    score_bayes[:,i] = opt - bayes\n",
    "    env[0,i] = max(0,np.sum(envy_vector(bayes,group_demands)))\n",
    "    po[0,i] = excess(bayes,budget)\n",
    "    prop[0,i] = np.sum(proportionality(bayes,group_demands,budget))\n",
    "    weights_alloc = waterfilling_weights_waste(weights, sorted_distribution, group_demands,budget)\n",
    "    score_weights[:,i] = opt - weights_alloc\n",
    "    env[1,i] = max(0,np.sum(envy_vector(weights_alloc,group_demands)))\n",
    "    po[1,i] = excess(weights_alloc,budget)\n",
    "    prop[1,i] = np.sum(proportionality(weights_alloc,group_demands,budget))\n",
    "    dynamic = waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)\n",
    "    score_dynamic[:,i] = opt - dynamic\n",
    "    env[2,i] = max(0,np.sum(envy_vector(dynamic,group_demands)))\n",
    "    po[2,i] = excess(dynamic,budget)\n",
    "    prop[2,i] = np.sum(proportionality(dynamic,group_demands,budget))\n",
    "    greedy_alloc = greedy(group_demands,budget)\n",
    "    score_greedy[:,i] = opt - greedy_alloc\n",
    "    env[3,i] = max(0,np.sum(envy_vector(greedy_alloc,group_demands)))\n",
    "    po[3,i] = excess(greedy_alloc,budget)\n",
    "    prop[3,i] = np.sum(proportionality(greedy_alloc,group_demands,budget))\n",
    "    threshold = constant_threshold(group_demands,budget,expected_demand)\n",
    "    score_threshold[:,i] = opt - threshold\n",
    "    env[4,i] = max(0,np.sum(envy_vector(threshold,group_demands)))\n",
    "    po[4,i] = excess(threshold,budget)\n",
    "    prop[4,i] = np.sum(proportionality(threshold,group_demands,budget))\n",
    "score_bayes = np.average(score_bayes, axis=1)\n",
    "score_weights = np.average(score_weights, axis=1)\n",
    "score_dynamic = np.average(score_dynamic, axis=1)\n",
    "score_greedy = np.average(score_greedy, axis=1)\n",
    "score_threshold = np.average(score_threshold, axis=1)\n",
    "env = np.average(env,axis=1)\n",
    "po = np.average(po,axis=1)\n",
    "prop = np.average(prop,axis=1)\n",
    "print('bayes, weights, dynamic, greedy, threshold')\n",
    "print('envy:')\n",
    "print(env)\n",
    "print('po')\n",
    "print(po)\n",
    "print('prop')\n",
    "print(prop)\n",
    "data_dict = {'Group':group,'Dynamic':score_dynamic,'Weights':score_weights, 'Bayes':score_bayes, 'Threshold':score_threshold,'Greedy':score_greedy}\n",
    "df_uniform = pd.DataFrame(data_dict).melt(id_vars=\"Group\")\n",
    "df_uniform.to_csv('GroupAllocationDifference.csv')\n",
    "fig = px.scatter(df_uniform, x=\"Group\", y=\"value\", color='variable')\n",
    "fig.update_layout(\n",
    "    title=\"Group by Group Allocation Difference between OPT and ALGs\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Difference\")\n",
    "fig.show()\n",
    "#[0.119     0.0288263 0.        0.666     0.       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Comparisons using Max Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = np.arange(n)\n",
    "group_expected_demands = np.zeros(n) + 1.5\n",
    "budget = 1.5*n\n",
    "score_weights = np.zeros((n,num_iterations))\n",
    "score_bayes = np.zeros((n,num_iterations))\n",
    "score_dynamic = np.zeros((n,num_iterations))\n",
    "score_greedy = np.zeros((n,num_iterations))\n",
    "score_threshold = np.zeros((n,num_iterations))\n",
    "env = np.zeros((5,num_iterations))\n",
    "po = np.zeros((5,num_iterations))\n",
    "prop = np.zeros((5,num_iterations))\n",
    "for i in range(num_iterations):\n",
    "    group_demands = np.random.randint(1, 3, n)\n",
    "    opt = waterfilling_waste(group_demands,budget)\n",
    "    bayes = waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)\n",
    "    score_bayes[:,i] = opt - bayes\n",
    "    env[0,i] = max(0,np.amax(envy_vector(bayes,group_demands)))\n",
    "    po[0,i] = excess(bayes,budget)\n",
    "    prop[0,i] = np.amax(proportionality(bayes,group_demands,budget))\n",
    "    weights_alloc = waterfilling_weights_waste(weights, sorted_distribution, group_demands,budget)\n",
    "    score_weights[:,i] = opt - weights_alloc\n",
    "    env[1,i] = max(0,np.amax(envy_vector(weights_alloc,group_demands)))\n",
    "    po[1,i] = excess(weights_alloc,budget)\n",
    "    prop[1,i] = np.amax(proportionality(weights_alloc,group_demands,budget))\n",
    "    dynamic = waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)\n",
    "    score_dynamic[:,i] = opt - dynamic\n",
    "    env[2,i] = max(0,np.amax(envy_vector(dynamic,group_demands)))\n",
    "    po[2,i] = excess(dynamic,budget)\n",
    "    prop[2,i] = np.amax(proportionality(dynamic,group_demands,budget))\n",
    "    greedy_alloc = greedy(group_demands,budget)\n",
    "    score_greedy[:,i] = opt - greedy_alloc\n",
    "    env[3,i] = max(0,np.amax(envy_vector(greedy_alloc,group_demands)))\n",
    "    po[3,i] = excess(greedy_alloc,budget)\n",
    "    prop[3,i] = np.amax(proportionality(greedy_alloc,group_demands,budget))\n",
    "    threshold = constant_threshold(group_demands,budget,expected_demand)\n",
    "    score_threshold[:,i] = opt - threshold\n",
    "    env[4,i] = max(0,np.amax(envy_vector(threshold,group_demands)))\n",
    "    po[4,i] = excess(threshold,budget)\n",
    "    prop[4,i] = np.amax(proportionality(threshold,group_demands,budget))\n",
    "score_bayes = np.average(score_bayes, axis=1)\n",
    "score_weights = np.average(score_weights, axis=1)\n",
    "score_dynamic = np.average(score_dynamic, axis=1)\n",
    "score_greedy = np.average(score_greedy, axis=1)\n",
    "score_threshold = np.average(score_threshold, axis=1)\n",
    "env = np.average(env,axis=1)\n",
    "po = np.average(po,axis=1)\n",
    "prop = np.average(prop,axis=1)\n",
    "print('bayes, weights, dynamic, greedy, threshold')\n",
    "print('envy:')\n",
    "print(env)\n",
    "print('po')\n",
    "print(po)\n",
    "print('prop')\n",
    "print(prop)\n",
    "data_dict = {'Group':group,'Dynamic':score_dynamic,'Weights':score_weights, 'Bayes':score_bayes, 'Threshold':score_threshold,'Greedy':score_greedy}\n",
    "df_uniform = pd.DataFrame(data_dict).melt(id_vars=\"Group\")\n",
    "df_uniform.to_csv('GroupAllocationDifference.csv')\n",
    "fig = px.scatter(df_uniform, x=\"Group\", y=\"value\", color='variable')\n",
    "fig.update_layout(\n",
    "    title=\"Group by Group Allocation Difference between OPT and ALGs\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Difference\")\n",
    "fig.show()\n",
    "#[0.119     0.0288263 0.        0.666     0.       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Comparisons using Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = np.arange(n)\n",
    "group_expected_demands = np.zeros(n) + 1.5\n",
    "budget = 1.5*n\n",
    "score_weights = np.zeros((n,num_iterations))\n",
    "score_bayes = np.zeros((n,num_iterations))\n",
    "score_dynamic = np.zeros((n,num_iterations))\n",
    "score_greedy = np.zeros((n,num_iterations))\n",
    "score_threshold = np.zeros((n,num_iterations))\n",
    "env = np.zeros((5,num_iterations))\n",
    "po = np.zeros((5,num_iterations))\n",
    "prop = np.zeros((5,num_iterations))\n",
    "linf = np.zeros((5,num_iterations))\n",
    "for i in range(num_iterations):\n",
    "    group_demands = np.random.randint(1, 3, n)\n",
    "    opt = waterfilling_waste(group_demands,budget)\n",
    "    bayes = waterfilling_bayesian(group_demands, opt_policy[(max_n-n):(max_n+1),:], budget, b_grid, grid_size)\n",
    "    score_bayes[:,i] = opt - bayes\n",
    "    env[0,i] = max(0,np.amax(envy_utility(bayes,group_demands)))\n",
    "    po[0,i] = excess(bayes,budget)\n",
    "    prop[0,i] = np.amax(proportionality_utility(bayes,group_demands,budget))\n",
    "    linf[0,i] = np.amax(score_bayes[:,i])\n",
    "    weights_alloc = waterfilling_weights_waste(weights, sorted_distribution, group_demands,budget)\n",
    "    score_weights[:,i] = opt - weights_alloc\n",
    "    env[1,i] = max(0,np.amax(envy_utility(weights_alloc,group_demands)))\n",
    "    po[1,i] = excess(weights_alloc,budget)\n",
    "    prop[1,i] = np.amax(proportionality_utility(weights_alloc,group_demands,budget))\n",
    "    linf[1,i] = np.amax(score_weights[:,i])\n",
    "    dynamic = waterfilling_dynamic_waste(group_expected_demands,group_demands,budget)\n",
    "    score_dynamic[:,i] = opt - dynamic\n",
    "    env[2,i] = max(0,np.amax(envy_utility(dynamic,group_demands)))\n",
    "    po[2,i] = excess(dynamic,budget)\n",
    "    prop[2,i] = np.amax(proportionality_utility(dynamic,group_demands,budget))\n",
    "    linf[2,i] = np.amax(score_dynamic[:,i])\n",
    "    greedy_alloc = greedy(group_demands,budget)\n",
    "    score_greedy[:,i] = opt - greedy_alloc\n",
    "    env[3,i] = max(0,np.amax(envy_utility(greedy_alloc,group_demands)))\n",
    "    po[3,i] = excess(greedy_alloc,budget)\n",
    "    prop[3,i] = np.amax(proportionality_utility(greedy_alloc,group_demands,budget))\n",
    "    linf[3,i] = np.amax(score_greedy[:,i])\n",
    "    threshold = constant_threshold(group_demands,budget,expected_demand)\n",
    "    score_threshold[:,i] = opt - threshold\n",
    "    env[4,i] = max(0,np.amax(envy_utility(threshold,group_demands)))\n",
    "    po[4,i] = excess(threshold,budget)\n",
    "    prop[4,i] = np.amax(proportionality_utility(threshold,group_demands,budget))\n",
    "    linf[4,i] = np.amax(score_threshold[:,i])\n",
    "score_bayes = np.average(score_bayes, axis=1)\n",
    "score_weights = np.average(score_weights, axis=1)\n",
    "score_dynamic = np.average(score_dynamic, axis=1)\n",
    "score_greedy = np.average(score_greedy, axis=1)\n",
    "score_threshold = np.average(score_threshold, axis=1)\n",
    "env = np.average(env,axis=1)\n",
    "po = np.average(po,axis=1)\n",
    "prop = np.average(prop,axis=1)\n",
    "linf = np.average(linf,axis=1)\n",
    "print('bayes, weights, dynamic, greedy, threshold')\n",
    "print('envy:')\n",
    "print(env)\n",
    "print('po')\n",
    "print(po)\n",
    "print('prop')\n",
    "print(prop)\n",
    "print('linf')\n",
    "print(linf)\n",
    "data_dict = {'Group':group,'Dynamic':score_dynamic,'Weights':score_weights, 'Bayes':score_bayes, 'Threshold':score_threshold,'Greedy':score_greedy}\n",
    "df_uniform = pd.DataFrame(data_dict).melt(id_vars=\"Group\")\n",
    "#df_uniform.to_csv('GroupAllocationDifference.csv')\n",
    "fig = px.scatter(df_uniform, x=\"Group\", y=\"value\", color='variable')\n",
    "fig.update_layout(\n",
    "    title=\"Group by Group Allocation Difference between OPT and ALGs\",\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Difference\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
